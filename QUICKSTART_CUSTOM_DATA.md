# å¿«é€Ÿå¼€å§‹ï¼šè‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### æ­¥éª¤ 1: åˆ›å»ºç¤ºä¾‹æ•°æ®é›†

```bash
# ç”Ÿæˆä¸€ä¸ªåŒ…å«10ä¸ªæ ·æœ¬çš„ç¤ºä¾‹æ•°æ®é›†
python prepare_dataset.py example --num-samples 10 --output example_dataset.json
```

**è¾“å‡º**:
```
âœ… æˆåŠŸåˆ›å»ºç¤ºä¾‹æ•°æ®é›†: example_dataset.json
   æ€»æ ·æœ¬æ•°: 10
```

### æ­¥éª¤ 2: éªŒè¯æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

```bash
# æ£€æŸ¥æ•°æ®é›†æ ¼å¼æ˜¯å¦æ­£ç¡®
python train_custom_data.py --dataset example_dataset.json --validate-only
```

**è¾“å‡º**:
```
âœ… æ•°æ®é›†æ ¼å¼æ­£ç¡®
ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:
   æ€»æ ·æœ¬æ•°: 10
   ç›®æ ‡èŒƒå›´: [-4.2345, -1.8765]
   ...
```

### æ­¥éª¤ 3: å¼€å§‹è®­ç»ƒ

```bash
# ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†è®­ç»ƒ DenseGNN æ¨¡å‹
python train_custom_data.py --dataset example_dataset.json --config config_custom_dataset.json
```

**è®­ç»ƒè¿‡ç¨‹**:
```
ğŸš€ å¼€å§‹è®­ç»ƒ DENSEGNN æ¨¡å‹...
   è®­ç»ƒé›†: 8 æ ·æœ¬
   éªŒè¯é›†: 1 æ ·æœ¬
   æµ‹è¯•é›†: 1 æ ·æœ¬

Epoch: 1
Train_MAE: 0.5234
Val_MAE: 0.4821
...
ğŸ‰ è®­ç»ƒå®Œæˆï¼
```

### æ­¥éª¤ 4: æŸ¥çœ‹ç»“æœ

```bash
# ç»“æœä¿å­˜åœ¨ results_custom_dataset/ ç›®å½•
ls results_custom_dataset/

# è¾“å‡º:
# best_val_model.pt
# best_test_model.pt
# predictions_*.csv
# history_*.json
```

---

## ğŸ“ ä½¿ç”¨è‡ªå·±çš„æ•°æ®

### ä» CIF æ–‡ä»¶

```bash
# 1. å‡†å¤‡ç›®æ ‡å€¼æ–‡ä»¶ (targets.csv)
echo "filename,target_value" > targets.csv
echo "structure1.cif,-3.5" >> targets.csv
echo "structure2.cif,-2.1" >> targets.csv

# 2. ä» CIF åˆ›å»ºæ•°æ®é›†
python prepare_dataset.py from-cif \
    --cif-dir ./my_cif_files/ \
    --target-file targets.csv \
    --output my_dataset.json

# 3. è®­ç»ƒ
python train_custom_data.py --dataset my_dataset.json
```

### ä» POSCAR æ–‡ä»¶

```bash
# ä» POSCAR æ–‡ä»¶åˆ›å»ºæ•°æ®é›†
python prepare_dataset.py from-poscar \
    --poscar-dir ./my_poscar_files/ \
    --target-file targets.csv \
    --output my_dataset.json

# è®­ç»ƒ
python train_custom_data.py --dataset my_dataset.json
```

### æ‰‹åŠ¨åˆ›å»º JSON

åˆ›å»º `my_dataset.json`:

```json
[
  {
    "jid": "sample_001",
    "atoms": {
      "lattice_mat": [[5.0, 0, 0], [0, 5.0, 0], [0, 0, 5.0]],
      "coords": [[0, 0, 0], [0.5, 0.5, 0.5]],
      "elements": ["Si", "Si"]
    },
    "formation_energy_peratom": -3.5,
    "text_description": "Silicon crystal"
  }
]
```

```bash
python train_custom_data.py --dataset my_dataset.json
```

---

## âš™ï¸ å¸¸ç”¨é…ç½®è°ƒæ•´

### ä¿®æ”¹æ¨¡å‹æ¶æ„

ç¼–è¾‘ `config_custom_dataset.json`:

```json
{
  "model": {
    "name": "densegnn",
    "densegnn_layers": 6,        // æ›´æ·±çš„æ¨¡å‹
    "hidden_features": 512,      // æ›´å¤§çš„éšè—ç»´åº¦
    "use_middle_fusion": true,
    "use_cross_modal_attention": true
  }
}
```

### è°ƒæ•´è®­ç»ƒå‚æ•°

```json
{
  "epochs": 500,              // æ›´å¤šè®­ç»ƒè½®æ•°
  "batch_size": 16,           // æ›´å°çš„æ‰¹æ¬¡ï¼ˆå†…å­˜ä¸è¶³æ—¶ï¼‰
  "learning_rate": 0.0001,    // æ›´å°çš„å­¦ä¹ ç‡
  "n_early_stopping": 100     // æ›´å®½æ¾çš„æ—©åœ
}
```

### ä¿®æ”¹æ•°æ®åˆ†å‰²

```json
{
  "train_ratio": 0.7,   // 70% è®­ç»ƒ
  "val_ratio": 0.15,    // 15% éªŒè¯
  "test_ratio": 0.15    // 15% æµ‹è¯•
}
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### é—®é¢˜ 1: å†…å­˜ä¸è¶³

**è§£å†³**:
```json
{
  "batch_size": 8,        // å‡å°æ‰¹æ¬¡
  "num_workers": 0,       // ç¦ç”¨å¤šè¿›ç¨‹
  "pin_memory": false     // ç¦ç”¨ pin memory
}
```

### é—®é¢˜ 2: è®­ç»ƒå¤ªæ…¢

**è§£å†³**:
```json
{
  "num_workers": 4,       // ä½¿ç”¨å¤šè¿›ç¨‹
  "save_dataloader": true // ç¼“å­˜æ•°æ®åŠ è½½å™¨
}
```

### é—®é¢˜ 3: æ•°æ®æ ¼å¼é”™è¯¯

**æ£€æŸ¥**:
```bash
python train_custom_data.py --dataset my_dataset.json --validate-only
```

---

## ğŸ“Š è¯„ä¼°æ¨¡å‹

### æŸ¥çœ‹è®­ç»ƒå†å²

```python
import json

with open("results_custom_dataset/history_val.json", "r") as f:
    history = json.load(f)

# ç»˜åˆ¶å­¦ä¹ æ›²çº¿
import matplotlib.pyplot as plt

plt.plot(history["mae"])
plt.xlabel("Epoch")
plt.ylabel("MAE")
plt.show()
```

### åˆ†æé¢„æµ‹ç»“æœ

```python
import pandas as pd

# è¯»å–é¢„æµ‹ç»“æœ
predictions = pd.read_csv("results_custom_dataset/predictions_best_val_model_test.csv")

# è®¡ç®—è¯¯å·®
predictions["error"] = predictions["prediction"] - predictions["target"]

# ç»Ÿè®¡
print(f"å¹³å‡ç»å¯¹è¯¯å·®: {predictions['error'].abs().mean():.4f}")
print(f"å‡æ–¹æ ¹è¯¯å·®: {(predictions['error']**2).mean()**0.5:.4f}")
```

---

## ğŸ“š å®Œæ•´æ–‡æ¡£

- **è¯¦ç»†æŒ‡å—**: `GUIDE_CUSTOM_DATASET.md`
- **DenseGNN æ–‡æ¡£**: `README_DenseGNN.md`
- **æ¨¡å‹é…ç½®**: `config_custom_dataset.json`

---

## ğŸ’¡ æç¤º

1. **ä»å°æ•°æ®é›†å¼€å§‹**: å…ˆç”¨å°‘é‡æ ·æœ¬æµ‹è¯•æµç¨‹
2. **éªŒè¯æ•°æ®**: è®­ç»ƒå‰åŠ¡å¿…éªŒè¯æ•°æ®æ ¼å¼
3. **ç›‘æ§è®­ç»ƒ**: ä½¿ç”¨ TensorBoard ç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
4. **ä¿å­˜æ£€æŸ¥ç‚¹**: å®šæœŸå¤‡ä»½ `best_*_model.pt`
5. **è®°å½•é…ç½®**: æ¯æ¬¡å®éªŒä¿å­˜é…ç½®æ–‡ä»¶

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ‰
