"""
ç¬¦å·å›å½’åˆ†æç¤ºä¾‹è„šæœ¬

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨interpretability_enhanced_v2æ¨¡å—ä¸­çš„ç¬¦å·å›å½’åŠŸèƒ½
ä»è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­å‘ç°å¯è§£é‡Šçš„æ•°å­¦å…¬å¼

ä½¿ç”¨æ–¹æ³•:
    python run_symbolic_regression_analysis.py --model_path <path_to_model> --data_path <path_to_data>

ä¾èµ–å®‰è£…:
    1. å®‰è£…PySR: pip install pysr
    2. å®‰è£…Julia: https://github.com/MilesCranmer/PySR#installation
    3. å®‰è£…å…¶ä»–ä¾èµ–: pip install torch dgl jarvis-tools transformers

ä½œè€…: SGA-V1.6
æ—¥æœŸ: 2025-12-04
"""

import os
import sys
import argparse
import torch
import warnings
warnings.filterwarnings('ignore')

from pathlib import Path
from tqdm import tqdm

# å¯¼å…¥å¯è§£é‡Šæ€§æ¨¡å—
from interpretability_enhanced_v2 import ComprehensiveExplainer


def main():
    parser = argparse.ArgumentParser(description='ç¬¦å·å›å½’åˆ†æ - ä»ç¥ç»ç½‘ç»œä¸­å‘ç°æ•°å­¦å…¬å¼')

    # å¿…éœ€å‚æ•°
    parser.add_argument('--model_path', type=str, required=True,
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ (.pt æˆ– .pth æ–‡ä»¶)')
    parser.add_argument('--data_path', type=str, required=True,
                        help='æ•°æ®é›†è·¯å¾„ (JARVISæ ¼å¼)')

    # å¯é€‰å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./symbolic_regression_results',
                        help='ç»“æœä¿å­˜ç›®å½• (é»˜è®¤: ./symbolic_regression_results)')
    parser.add_argument('--max_samples', type=int, default=500,
                        help='æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 500, Noneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æ ·æœ¬)')
    parser.add_argument('--batch_size', type=int, default=16,
                        help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 16)')
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®¾å¤‡ (cuda æˆ– cpu, é»˜è®¤: cuda)')
    parser.add_argument('--property', type=str, default='formation_energy_peratom',
                        help='é¢„æµ‹çš„ææ–™å±æ€§ (é»˜è®¤: formation_energy_peratom)')

    # PySRå‚æ•°
    parser.add_argument('--niterations', type=int, default=100,
                        help='ç¬¦å·å›å½’è¿­ä»£æ¬¡æ•° (é»˜è®¤: 100)')
    parser.add_argument('--maxsize', type=int, default=20,
                        help='å…¬å¼æœ€å¤§å¤æ‚åº¦ (é»˜è®¤: 20)')

    args = parser.parse_args()

    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        args.device = 'cpu'

    print("\n" + "="*80)
    print("ğŸ”¬ ç¬¦å·å›å½’å¯è§£é‡Šæ€§åˆ†æ")
    print("="*80)
    print(f"\né…ç½®:")
    print(f"  æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"  æ•°æ®è·¯å¾„: {args.data_path}")
    print(f"  ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"  æœ€å¤§æ ·æœ¬æ•°: {args.max_samples}")
    print(f"  è®¾å¤‡: {args.device}")
    print(f"  å±æ€§: {args.property}")

    # ==================== 1. åŠ è½½æ¨¡å‹ ====================
    print("\n" + "="*80)
    print("ğŸ“¦ [1/4] åŠ è½½æ¨¡å‹...")
    print("="*80)

    if not os.path.exists(args.model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
        sys.exit(1)

    try:
        # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint = torch.load(args.model_path, map_location=args.device)

        # å¦‚æœcheckpointæ˜¯å­—å…¸ï¼Œæå–æ¨¡å‹çŠ¶æ€
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                model_state = checkpoint['model_state_dict']
            elif 'model' in checkpoint:
                model_state = checkpoint['model']
            else:
                model_state = checkpoint
        else:
            model_state = checkpoint

        print("   âœ“ æ¨¡å‹æ£€æŸ¥ç‚¹å·²åŠ è½½")

        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ¨¡å‹æ¶æ„å¯¼å…¥å’Œåˆå§‹åŒ–
        # ç¤ºä¾‹ï¼šå‡è®¾ä½¿ç”¨ALIGNNæ¨¡å‹
        print("   âš ï¸ æ³¨æ„: éœ€è¦æ ¹æ®å®é™…æ¨¡å‹æ¶æ„åˆå§‹åŒ–æ¨¡å‹")
        print("   æç¤º: ä¿®æ”¹æ­¤è„šæœ¬ä¸­çš„æ¨¡å‹åˆå§‹åŒ–éƒ¨åˆ†")

        # TODO: æ›¿æ¢ä¸ºå®é™…çš„æ¨¡å‹åˆå§‹åŒ–ä»£ç 
        # from models.alignn import ALIGNN
        # model = ALIGNN(...)
        # model.load_state_dict(model_state)
        # model = model.to(args.device)
        # model.eval()

        # ä¸´æ—¶å ä½ç¬¦
        model = None

        if model is None:
            print("   âŒ è¯·åœ¨è„šæœ¬ä¸­é…ç½®æ­£ç¡®çš„æ¨¡å‹åˆå§‹åŒ–ä»£ç ")
            print("   æç¤º: æŸ¥çœ‹ models/ ç›®å½•ä¸­çš„æ¨¡å‹å®šä¹‰")
            sys.exit(1)

    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # ==================== 2. åŠ è½½æ•°æ® ====================
    print("\n" + "="*80)
    print("ğŸ“Š [2/4] åŠ è½½æ•°æ®...")
    print("="*80)

    if not os.path.exists(args.data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_path}")
        sys.exit(1)

    try:
        # TODO: æ ¹æ®å®é™…æ•°æ®æ ¼å¼åŠ è½½æ•°æ®
        # from data import get_test_loader
        # test_loader = get_test_loader(
        #     data_path=args.data_path,
        #     batch_size=args.batch_size,
        #     property_name=args.property
        # )

        test_loader = None

        if test_loader is None:
            print("   âŒ è¯·åœ¨è„šæœ¬ä¸­é…ç½®æ­£ç¡®çš„æ•°æ®åŠ è½½ä»£ç ")
            print("   æç¤º: æŸ¥çœ‹ data.py ä¸­çš„æ•°æ®åŠ è½½å‡½æ•°")
            sys.exit(1)

        print(f"   âœ“ æ•°æ®é›†å·²åŠ è½½")

    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # ==================== 3. åˆå§‹åŒ–è§£é‡Šå™¨ ====================
    print("\n" + "="*80)
    print("ğŸ”§ [3/4] åˆå§‹åŒ–å¯è§£é‡Šæ€§åˆ†æå™¨...")
    print("="*80)

    try:
        # åˆå§‹åŒ–tokenizer (å¦‚æœæ¨¡å‹ä½¿ç”¨æ–‡æœ¬è¾“å…¥)
        try:
            from transformers import AutoTokenizer
            tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
            print("   âœ“ Tokenizerå·²åŠ è½½")
        except Exception as e:
            print(f"   âš ï¸ TokenizeråŠ è½½å¤±è´¥: {e}")
            tokenizer = None

        # åˆå§‹åŒ–è§£é‡Šå™¨
        explainer = ComprehensiveExplainer(
            model=model,
            tokenizer=tokenizer,
            device=args.device
        )

        print("   âœ“ è§£é‡Šå™¨åˆå§‹åŒ–å®Œæˆ")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–è§£é‡Šå™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # ==================== 4. è¿è¡Œç¬¦å·å›å½’åˆ†æ ====================
    print("\n" + "="*80)
    print("ğŸ§® [4/4] è¿è¡Œç¬¦å·å›å½’åˆ†æ...")
    print("="*80)

    try:
        # æ£€æŸ¥PySRæ˜¯å¦å®‰è£…
        try:
            import pysr
            print("   âœ“ PySRå·²å®‰è£…")
        except ImportError:
            print("   âŒ PySRæœªå®‰è£…")
            print("   è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
            print("   1. pip install pysr")
            print("   2. python -c 'import pysr; pysr.install()'")
            print("   æˆ–è®¿é—®: https://github.com/MilesCranmer/PySR")
            sys.exit(1)

        # è¿è¡Œç¬¦å·å›å½’
        model_sr, results = explainer.extract_symbolic_features(
            test_loader=test_loader,
            save_dir=args.save_dir,
            max_samples=args.max_samples
        )

        if model_sr is not None and results is not None:
            print("\n" + "="*80)
            print("âœ… ç¬¦å·å›å½’åˆ†ææˆåŠŸå®Œæˆ!")
            print("="*80)

            print(f"\nğŸ“Š ä¸»è¦ç»“æœ:")
            print(f"  æ ·æœ¬æ•°: {results['num_samples']}")
            print(f"  ç‰¹å¾ç»´åº¦: {results['feature_dim']}")

            print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
            metrics = results['metrics']
            print(f"  MAE:  {metrics['mae']:.4f}")
            print(f"  RMSE: {metrics['rmse']:.4f}")
            print(f"  RÂ²:   {metrics['r2']:.4f}")

            print(f"\nğŸ”¬ ä¸ç¥ç»ç½‘ç»œå¯¹æ¯”:")
            nn_comp = results['nn_comparison']
            print(f"  ç¥ç»ç½‘ç»œ MAE: {nn_comp['mae_nn']:.4f}")
            print(f"  MAE æ¯”ç‡: {nn_comp['mae_ratio']:.2%}")
            print(f"  RÂ² å·®è·: {nn_comp['r2_diff']:+.4f}")

            if results['best_formula']:
                print(f"\nğŸ¯ æœ€ä½³ç¬¦å·å…¬å¼:")
                print(f"  {results['best_formula']}")

            print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.save_dir}")
            print("   - symbolic_regression_formulas.txt  (æ‰€æœ‰å…¬å¼)")
            print("   - symbolic_regression_results.json  (è¯¦ç»†ç»“æœ)")
            print("   - symbolic_regression_model.pkl     (PySRæ¨¡å‹)")

        else:
            print("\nâŒ ç¬¦å·å›å½’åˆ†æå¤±è´¥")
            sys.exit(1)

    except Exception as e:
        print(f"\nâŒ è¿è¡Œç¬¦å·å›å½’å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    print("\n" + "="*80)
    print("ğŸ‰ åˆ†æå®Œæˆ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
